{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e7c2f4-c7c2-4070-a2b8-921b6b879ccb",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c837d8-485f-4252-9364-10b689794246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b22113ca-7335-4be0-baf3-a41eeca33bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196e1e4-5128-4ebc-9b64-ca795b1257c7",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc83bed4-aa90-4f9f-93ae-ab887653509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Settings ===\n",
    "image_size = (128, 128)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60df69c9-e8e9-4bb7-924a-2110c0338537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_filepaths_and_class_labels(data_dir):\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    filepaths = []\n",
    "    class_indices = []\n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        class_folder = os.path.join(data_dir, class_name)\n",
    "        if not os.path.isdir(class_folder):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder):\n",
    "            if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                filepaths.append(os.path.join(class_folder, filename))\n",
    "                class_indices.append(class_index)\n",
    "    return filepaths, class_indices, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75d6d08-9205-45bb-ba68-537a168644e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_cv(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, image_size)\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce75f88-a8a3-427e-8a2d-8d214f0f29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(index, total_classes):\n",
    "    encoded = np.zeros(total_classes, dtype=np.float32)\n",
    "    encoded[index] = 1.0\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ac08681-2bb8-4fb4-9cef-277622691bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_dataset_cv(data_dir):\n",
    "    filepaths, class_indices, class_names = get_image_filepaths_and_class_labels(data_dir)\n",
    "    total_classes = len(class_names)\n",
    "    print(f\"Found {len(filepaths)} images across {total_classes} classes.\")\n",
    "    \n",
    "    image_data = []\n",
    "    encoded_labels = []\n",
    "    for path, label in zip(filepaths, class_indices):\n",
    "        image = preprocess_image_cv(path)\n",
    "        one_hot_label = to_one_hot(label, total_classes)\n",
    "        image_data.append(image)\n",
    "        encoded_labels.append(one_hot_label)\n",
    "    return image_data, encoded_labels, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c37f18-9a12-4466-95f5-61fffc961775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_images_and_labels(image_data, encoded_labels, batch_size):\n",
    "    all_batches = []\n",
    "    for start in range(0, len(image_data), batch_size):\n",
    "        batch_images = np.array(image_data[start:start+batch_size])\n",
    "        batch_labels = np.array(encoded_labels[start:start+batch_size])\n",
    "        all_batches.append((batch_images, batch_labels))\n",
    "    return all_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f970be-abac-49ce-b988-0c7599411f2a",
   "metadata": {},
   "source": [
    "# Load dataset and create batches\n",
    "image_data, encoded_labels, class_names = load_image_dataset_cv(\"New Plant Diseases Dataset(Augmented)/train\")\n",
    "batches = batch_images_and_labels(image_data, encoded_labels, batch_size)\n",
    "\n",
    "# Display information about the first batch\n",
    "first_batch_imgs, first_batch_lbls = batches[0]\n",
    "print(\"First batch shapes:\", first_batch_imgs.shape, first_batch_lbls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a637d7-7ff5-451b-8713-fb35055d61d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70295 images across 38 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load train data\n",
    "train_images, train_labels, class_names = load_image_dataset_cv(\"New Plant Diseases Dataset(Augmented)/train\")\n",
    "\n",
    "# Create train batches\n",
    "train_batches = batch_images_and_labels(train_images, train_labels, batch_size)\n",
    "\n",
    "# Inspect\n",
    "print(\"Train batch shape:\", train_batches[0][0].shape, train_batches[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eed2e49-4b6f-4340-bd05-ccd1c661c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(train_batches):\n",
    "    for batch_images, batch_labels in train_batches:\n",
    "        yield batch_images, batch_labels\n",
    "\n",
    "def convert_batches_to_tf_dataset(train_batches):\n",
    "    first_batch = train_batches[0]\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=first_batch[0].shape[1:], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=first_batch[1].shape[1:], dtype=tf.float32)\n",
    "    )\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: batch_generator(train_batches),\n",
    "        output_signature=(tf.TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32),\n",
    "                          tf.TensorSpec(shape=(None, len(train_batches[0][1][0])), dtype=tf.float32))\n",
    "    )\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82ac55c6-9c95-4be7-b4c2-6b1201f0652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = convert_batches_to_tf_dataset(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb069e22-a0a4-4750-9665-9f95e443db19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 38), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d379f9af-d485-4f48-be44-cbd42c665ad6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
